{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "> 该项目基于约会人员的分类数据，调用sklearn类库进行分类， 重点联系机器学习项目处理数据的流程\n",
    ">\n",
    "> 我的朋友艾伦一直使用在线的约会网站寻找合适的约会对象，尽管约会网站会推荐不同的人选， 但她并不喜欢每一个人，经过一番总结，她交往过三种类型的人\n",
    ">> * 不喜欢的人\n",
    ">> * 魅力一般的人\n",
    ">> * 极具魅力的人\n",
    "> \n",
    "> 尽管发现了上述规律， 但是艾伦仍无法将约会网站推荐的匹配对象归入恰当的类别，请你根据给定的数据进行分析， 帮助艾伦把新的匹配对象划分到确切的类中\n",
    ">\n",
    "> 基于sklearn库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入相应的包 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 获取数据\n",
    "> 艾伦收集了一些约会数据，将这些数据保存到了datingSet.txt中，每个样本数据占据一行， 总共1000行。艾伦的样本主要包含下面的特征：\n",
    ">> * 每年获得的飞行常客里程数\n",
    ">> * 玩视频游戏所耗时间百分比\n",
    ">> * 每周消费的冰激凌公升数\n",
    ">\n",
    "> 首先，需要将这些数据解析成可用的numpy解析程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ffMiles percentTats  iceCream labels\n",
      "0   40920    8.326976  0.953952      3\n",
      "1   14488    7.153469  1.673904      2\n",
      "2   26052    1.441871  0.805124      1\n",
      "3   75136   13.147394  0.428964      1\n",
      "4   38344    1.669788  0.134296      1\n",
      "       ffMiles percentTats  iceCream labels\n",
      "count     1000        1000      1000   1000\n",
      "unique     990         940      1000      3\n",
      "top          0    0.000000  1.624296      1\n",
      "freq         5          61         1    342\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      "ffMiles        1000 non-null object\n",
      "percentTats    1000 non-null object\n",
      "iceCream       1000 non-null object\n",
      "labels         1000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.3+ KB\n",
      "None\n",
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "# 从文件中读取数据，然后转换成DataFrame\n",
    "filename = \"datingTestSet2.txt\"\n",
    "data = []\n",
    "with open(filename, \"r\") as fr:\n",
    "    for line in fr:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        data.append(line)\n",
    "\n",
    "names = ['ffMiles','percentTats', 'iceCream', 'labels']\n",
    "dataset = pd.DataFrame(data, columns=names)\n",
    "print(dataset.head())\n",
    "print(dataset.describe())\n",
    "print(dataset.info())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 分离评估数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## array = dataset.values\n",
    "X = array[:, 0:3].astype(float)\n",
    "Y = array[:, 3]\n",
    "validation_value = 0.2\n",
    "seed = 5\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_value, random_state=seed) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN : 0.7949999999999999 (0.06254998001598401)\n",
      "SVM : 0.35875 (0.0344827855603343)\n",
      "CART : 0.9412499999999999 (0.023082731640774245)\n",
      "NB : 0.9349999999999999 (0.014577379737113235)\n"
     ]
    }
   ],
   "source": [
    "# 评估算法的基准\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "models = {}\n",
    "models['KNN'] = KNeighborsClassifier()\n",
    "models['SVM'] = SVC()\n",
    "models['CART'] = DecisionTreeClassifier()\n",
    "models['NB'] = GaussianNB()\n",
    "\n",
    "# 评估\n",
    "results = []\n",
    "for key in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_result = cross_val_score(models[key], X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_result)\n",
    "    print(\"{} : {} ({})\".format(key, cv_result.mean(), cv_result.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'从上面可以看出，决策树和朴素贝叶斯算法效果好一些， 支持向量机表现效果差，可能是数据没有标准化的原因，我们下面对数据\\n进行标准化之后，统一再比较，使用自动处理流程'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 评估算法 --- 箱线图\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(models.keys())\n",
    "plt.show()\n",
    "\n",
    "\"\"\"从上面可以看出，决策树和朴素贝叶斯算法效果好一些， 支持向量机表现效果差，可能是数据没有标准化的原因，我们下面对数据\n",
    "进行标准化之后，统一再比较，使用自动处理流程\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScalerKNN : 0.9487499999999999 (0.021250000000000005)\n",
      "ScalerSVM : 0.9549999999999998 (0.025124689052802223)\n",
      "ScalerCART : 0.9475 (0.02222048604328897)\n",
      "ScalerNB : 0.93625 (0.014197270864500672)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'经过特征缩放之后，还是SVM和KNN比较好，下面就从这两个模型中进行进一步的改进'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标准化处理数据\n",
    "pipelines = {}\n",
    "pipelines['ScalerKNN'] = Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsClassifier())])\n",
    "pipelines['ScalerSVM'] = Pipeline([('Scaler', StandardScaler()), ('SVM', SVC())])\n",
    "pipelines['ScalerCART'] = Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeClassifier())])\n",
    "pipelines['ScalerNB'] = Pipeline([('Scaler', StandardScaler()), ('NB', GaussianNB())])\n",
    "\n",
    "results = []\n",
    "for key in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_result = cross_val_score(pipelines[key], X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_result)\n",
    "    print(\"{} : {} ({})\".format(key, cv_result.mean(), cv_result.std()))\n",
    "\n",
    "# 箱线图\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Scaled Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(models.keys())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\"\"\"经过特征缩放之后，还是SVM和KNN比较好，下面就从这两个模型中进行进一步的改进\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 优化模型\n",
    "> * 算法调参\n",
    "> * 集成算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 算法调参 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优:0.95875  使用 {'n_neighbors': 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'最好的k是11'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 算法调参 --- KNN\n",
    "rescaledX = MinMaxScaler().fit_transform(X_train)\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 7,  9, 11, 13, 15, 17, 19, 21]}\n",
    "model = KNeighborsClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=rescaledX, y=Y_train)\n",
    "print(\"最优:{}  使用 {}\".format(grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# cv_results = zip(grid_result.cv_results_['mean_test_score'], grid_result.cv_results_['std_test_score'], grid_result.cv_results_['params']) \n",
    "# for mean, std, param in cv_results:\n",
    "#     print('%f (%f) with %r' % (mean, std, param))\n",
    "\n",
    "\n",
    "\"\"\"最好的k是11\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优:0.96  使用 {'C': 1.5, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'关于SVM的最优参数 C=2.0  kernel = rbf'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 算法调参 --- SVM\n",
    "rescaledX = StandardScaler().fit_transform(X_train)\n",
    "param_grid = {}\n",
    "param_grid['C'] = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "param_grid['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring=scoring)\n",
    "grid_result = grid.fit(X=rescaledX, y=Y_train)\n",
    "\n",
    "print(\"最优:{}  使用 {}\".format(grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# cv_results = zip(grid_result.cv_results_['mean_test_score'], grid_result.cv_results_['std_test_score'], grid_result.cv_results_['params']) \n",
    "# for mean, std, param in cv_results:\n",
    "#     print('%f (%f) with %r' % (mean, std, param))\n",
    "\n",
    "    \n",
    "\"\"\"关于SVM的最优参数 C=2.0  kernel = rbf\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 集成算法\n",
    "> 除了调参， 提高算法准确度的方法是集成算法。 下面对四种集成算法进行比较，进一步提高算法的准确度\n",
    ">> * 装袋算法： 随机森林(RF)和极端随机树(ET)\n",
    ">> * 提升算法： AdaBoost(AB) 和随机梯度上升(GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledAB: 0.798750 (0.042001)\n",
      "ScaledGBM: 0.955000 (0.021794)\n",
      "ScaledRF: 0.952500 (0.015612)\n",
      "ScaledET: 0.952500 (0.020767)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'随机梯度上升也许值得进一步分析， 因为具有良好的准确度，并且数据比较紧凑'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 集成算法\n",
    "ensembles = {}\n",
    "ensembles['ScaledAB'] = Pipeline([('Scaler', StandardScaler()), ('AB', AdaBoostClassifier())])\n",
    "ensembles['ScaledGBM'] = Pipeline([('Scaler', StandardScaler()), ('GBM', GradientBoostingClassifier())])\n",
    "ensembles['ScaledRF'] = Pipeline([('Scaler', StandardScaler()), ('RF', RandomForestClassifier())])\n",
    "ensembles['ScaledET'] = Pipeline([('Scaler', StandardScaler()), ('ET', ExtraTreesClassifier())])\n",
    "\n",
    "results = []\n",
    "for key in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_result = cross_val_score(ensembles[key], X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_result)\n",
    "    print('%s: %f (%f)' % (key, cv_result.mean(), cv_result.std()))\n",
    "\n",
    "# 集成算法 --- 箱线图\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(ensembles.keys())\n",
    "plt.show()\n",
    "\n",
    "\"\"\"随机梯度上升也许值得进一步分析， 因为具有良好的准确度，并且数据比较紧凑\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优： 0.9575 使用 {'n_estimators': 50}\n",
      "0.947500 (0.020000) with {'n_estimators': 10}\n",
      "0.957500 (0.018708) with {'n_estimators': 50}\n",
      "0.955000 (0.021794) with {'n_estimators': 100}\n",
      "0.955000 (0.023184) with {'n_estimators': 200}\n",
      "0.952500 (0.023585) with {'n_estimators': 300}\n",
      "0.953750 (0.023083) with {'n_estimators': 400}\n",
      "0.953750 (0.023083) with {'n_estimators': 500}\n",
      "0.953750 (0.023083) with {'n_estimators': 600}\n",
      "0.953750 (0.023083) with {'n_estimators': 700}\n",
      "0.953750 (0.023083) with {'n_estimators': 800}\n",
      "0.953750 (0.023083) with {'n_estimators': 900}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'最优参数200个分类器的效果比较好'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 集成算法调参 --- GBM\n",
    "rescaledX = StandardScaler().fit_transform(X_train)\n",
    "param_grid = {'n_estimators': [10, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900]}\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(X=rescaledX, y=Y_train)\n",
    "\n",
    "print('最优： %s 使用 %s' % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "cv_results = zip(grid_result.cv_results_['mean_test_score'], grid_result.cv_results_['std_test_score'], grid_result.cv_results_['params'])\n",
    "for mean, std, param in cv_results:\n",
    "    print('%f (%f) with %r' % (mean, std, param))\n",
    "\n",
    "\"\"\"最优参数200个分类器的效果比较好\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  确定最终模型\n",
    "> 通过前面对算法的评估发现 支持向量机具有最佳的准确度。 所以将会用支持向量机（SVM）, 通过训练集数据生成算法模型， 并通过预留的评估数据集\n",
    "来评估模型。 在算法评估过程中， 支持向量机SVM对正态化的数据具有较高的准确度。所以对训练集做正态化处理， 对评估数据集也做相同的处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 3, the real answer is: 3\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 2, the real answer is: 2\n",
      "the classifier came back with: 1, the real answer is: 1\n",
      "the classifier came back with: 3, the real answer is: 2\n",
      "the total error rate is : 0.06\n"
     ]
    }
   ],
   "source": [
    "# 模型最终化\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = SVC(C=1.5, kernel='rbf')\n",
    "#model = KNeighborsClassifier(n_neighbors=11)\n",
    "model = GradientBoostingClassifier(n_estimators=50)\n",
    "model.fit(rescaledX, Y_train)\n",
    "\n",
    "# 评估模型\n",
    "rescaled_validationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaled_validationX)\n",
    "\n",
    "#  书上的评估方式，最后用向量机处理完毕之后，误差是0.7\n",
    "errorCount = 0.0\n",
    "for i in range(len(predictions)):\n",
    "    print(\"the classifier came back with: {}, the real answer is: {}\".format(predictions[i], Y_validation[i]))\n",
    "    if (predictions[i] != Y_validation[i]):\n",
    "        errorCount += 1.0\n",
    "print(\"the total error rate is : {}\".format(errorCount/float(len(predictions))))  \n",
    "\n",
    "# 评估算法模型\n",
    "# print(\"accuracy_score\\n\",accuracy_score(Y_validation, predictions))\n",
    "# print(\"\\nconfusion_matrix\\n\", pd.DataFrame(confusion_matrix(Y_validation, predictions),columns=np.unique(Y_validation), index=np.unique(Y_validation)))\n",
    "# print(\"\\nclassification_report\\n\", classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结：\n",
    "> 这次通过机器学习实战的第一个约会人员分类的项目，又学习了一遍sklearn机器学习的过程，下面在总结一下框架\n",
    "> * 定义问题\n",
    ">> * 导入包\n",
    ">> * 导入数据集（可能是txt格式的，就需要转换成numpy可以解析的数据）\n",
    "> * 查看数据\n",
    ">> * 查看数据的一般特性，形状shape，浏览head()，基本的统计特征describe()， info()看是否有缺失值， 如果有缺失值，再处理\n",
    ">> * 通过图标可视化特征，包括一维数据可视化和多维之间的相关性\n",
    ">>> * 一维数据可视化 hist(), 密度分布图\n",
    ">>> * 多维数据相关性 相关矩阵\n",
    "> * 数据集处理\n",
    ">> * 划分数据集\n",
    ">> * 归一化(StandardScaler()、MinMaxScaler())\n",
    "> * 评估模型\n",
    ">> * 建立一些模型， 然后k交叉验证\n",
    ">> * 创建箱线图， 观察，调出两三种效果比较好的\n",
    "> * 优化模型\n",
    ">> * 模型调参\n",
    ">> * 集成算法（随机森林，AdaBoost， 梯度上升， 极端随机树）\n",
    "> * 确定最终模型，进行预测和评估"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
